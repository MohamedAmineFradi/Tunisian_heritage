# ==================== Tunisian Heritage RAG - Environment Configuration ====================
# Copy this file to .env and adjust values as needed

# ==================== n8n Configuration ====================
N8N_HOST=localhost
WEBHOOK_URL=http://localhost:5678/
N8N_BASIC_AUTH_ACTIVE=true
N8N_BASIC_AUTH_USER=admin
N8N_BASIC_AUTH_PASSWORD=admin
TZ=Africa/Tunis
N8N_LOG_LEVEL=info

# ==================== Service URLs ====================
OLLAMA_URL=http://localhost:11434
QDRANT_URL=http://localhost:6333

# ==================== Qdrant Collection Configuration ====================
QDRANT_COLLECTION=heritage_transcripts
QDRANT_DISTANCE=Cosine
QDRANT_VECTOR_SIZE=768

# ==================== Model Configuration ====================
# Router model for query classification
ROUTER_MODEL=llama3:8b

# Generation model for answers
GEN_MODEL=mixtral

# Embedding model - nomic-embed-text is lightweight and accurate
EMBED_MODEL=nomic-embed-text

# Answer language preference: ar (Arabic) or fr (French)
ANSWER_LANG=ar

# ==================== Ingestion Optimization ====================
# Number of embeddings to process in parallel (adjust based on CPU)
MAX_WORKERS=4

# Batch size for Qdrant upserts (higher = faster but more memory)
BATCH_SIZE=10

# Chunk size and overlap for text splitting
CHUNK_SIZE=600
CHUNK_OVERLAP=50

# ==================== Performance Tuning ====================
# Ollama parallel requests (adjust based on GPU/CPU capacity)
OLLAMA_NUM_PARALLEL=4

# Maximum models to keep loaded in memory
OLLAMA_MAX_LOADED_MODELS=2

# HTTP request timeout in seconds
REQUEST_TIMEOUT=30

# ==================== Cache Configuration ====================
# Enable query result caching to reduce redundant API calls
ENABLE_CACHE=true

# Cache TTL in seconds (default: 1 hour)
CACHE_TTL=3600

# Cache file location
CACHE_FILE=.cache/query_cache.json

# ==================== Data Configuration ====================
# Path to transcript data directory
DATA_DIR=./data/transcripts

